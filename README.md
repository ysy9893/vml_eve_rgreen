# Paper Study

---

Co-written by Soyeon Yoon, Jiyeon Jinnie Jung

Licensed Visual Media Lab @KAIST

---

## Tips

[Tips and Tricks](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/Tips%20and%20Tricks%20b0449d21b16840b1b66cf0469ff14411.md)

## Graphics

[Rendering](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/Rendering%20e61234380d8e46ae9f82afa31090547f.md)

## Papers

- **Pix2Pix Isola et al. [[project](https://phillipi.github.io/pix2pix/)][[summary](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/pix2pix%208376070f7da54a6bb1a9bc73805df563/pix2pix_summary%20845b8e76a30c443e8980ab30f0de97ae.md)][[notes](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/pix2pix%208376070f7da54a6bb1a9bc73805df563.md)]**
- **CycleGAN Zhu et al. [[project](https://junyanz.github.io/CycleGAN/)][[summary](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/CycleGAN%20(Unsupervised)%20d62c159362424283a87f650643492498/CycleGAN_summary%20b64f9f84a8f546049ca1690ac2cce399.md)][[notes](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/CycleGAN%20(Unsupervised)%20d62c159362424283a87f650643492498.md)]**
- GAN Goodfellow et al. [[summary](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/GAN%207ec9ed49b4314d75a25f075cfb41207a/GAN_summary%208f5edf64c9fc4996b9b8577afee084a0.md)][[notes](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/GAN%207ec9ed49b4314d75a25f075cfb41207a.md)]
- DCGAN Radford et al. [project][notes]
- StarGAN Choi et al. [[project](https://github.com/yunjey/stargan)][notes]
- MUNIT Huang et al. [[project](https://github.com/NVlabs/MUNIT)] —-3
- FUNIT Liu et al. [[project](https://nvlabs.github.io/FUNIT/)]
- SPADE Park et al. [[project](https://nvlabs.github.io/SPADE/)]
- **AdaIN Huang et al. [[project](https://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Arbitrary_Style_Transfer_ICCV_2017_paper.pdf)][[video](https://www.youtube.com/watch?v=IIRxJvW6bE4)] —-2**
- Perceptual Loss Johnson et al. [[project](https://cs.stanford.edu/people/jcjohns/eccv16/)]
- TUNIT [[project](https://github.com/clovaai/tunit)]
- ProGAN Karras et al. [[project](https://github.com/tkarras/progressive_growing_of_gans)]
- StyleGAN Karras et al. [[project](https://github.com/NVlabs/stylegan)]
- LPIPS [[link](https://richzhang.github.io/PerceptualSimilarity/)]
- Real-Time User-Guided Image Colorization [[project](https://richzhang.github.io/ideepcolor/)][[video](https://www.youtube.com/watch?v=rp5LUSbdsys)]
- Everybody Dance Now [[projet](https://carolineec.github.io/everybody_dance_now/)]
- NeRF Mildenhall et al. [[project](https://www.matthewtancik.com/nerf)][[notes](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/NeRF%2060dba35e6d914ba59e0a6fb46935af70.md)]

---

[pix2pix](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/pix2pix%208376070f7da54a6bb1a9bc73805df563.md)

[CycleGAN (Unsupervised)](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/CycleGAN%20(Unsupervised)%20d62c159362424283a87f650643492498.md)

[DCGAN](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/DCGAN%20c591c03863df4b1eb873f3948bb1e263.md)

[MUNIT](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/MUNIT%20f8f7473d96ee4cc4b4a8ea80dfc9e9a5.md)

[GAN](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/GAN%207ec9ed49b4314d75a25f075cfb41207a.md)

[NeRF](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/NeRF%2060dba35e6d914ba59e0a6fb46935af70.md)

[starGAN](Paper%20Study%2068e3ebe9fd7a4c5698dd326b5ac62910/starGAN%207866cd2463f34d4e809bfa5e234518f2.md)
