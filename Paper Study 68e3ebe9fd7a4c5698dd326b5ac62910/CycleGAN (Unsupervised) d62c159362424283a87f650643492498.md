# CycleGAN (Unsupervised)

## Introduction

![Untitled](CycleGAN%20(Unsupervised)%20d62c159362424283a87f650643492498/Untitled.png)

- Learning to translate an image from a source domain X to a target domain Y in the absence of paired training examples.

Cycle Consistency Loss

![Untitled](CycleGAN%20(Unsupervised)%20d62c159362424283a87f650643492498/Untitled%201.png)

## Formulation

2 Discriminators 

- Dx : Distinguish btw images {x} and translated images {F(y)}
- Dy: Distinguish btw images {y} and translated images {G(x)}

**Adversarial Loss**: Matching the distribution of generated images to the data distribution in the target domain. 

![Untitled](CycleGAN%20(Unsupervised)%20d62c159362424283a87f650643492498/Untitled%202.png)

**Cycle Consistency Loss**의 필요성 : 

데이터의 양이 충분할 때, 네트워크는 같은 인풋 이미지 세트를 타겟 도메인 이미지로 랜덤하게 맵핑하게 된다 (왜냐면 adversarial loss를 통해서 학습한 맵핑이 타겟 데이터 분포를 따르는 아웃풋 이미지를 랜덤하게 생성하기 때문)

즉, 우리가 원하는 아웃풋(이미지)을 만들어낼 수 없다. 

Bring x back to the original image 

Forward Cycle Consistency: x → G(x) → F(G(x)) ≈ x

Backward cycle consistency: y → F(y) → G(F(y)) ≈ y